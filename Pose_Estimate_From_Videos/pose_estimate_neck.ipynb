{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900b170-98d4-470e-83f4-817c5aad937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739852993.404438 4131831 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1 Pro\n",
      "W0000 00:00:1739852993.471320 4142321 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1739852993.486105 4142321 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video.\n",
      "Finished processing.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math as m\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n",
    "    return m.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    \"\"\"Calculate the angle between two points.\"\"\"\n",
    "    if y1 == y2:\n",
    "        return 0\n",
    "\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    theta = m.atan2(delta_y, delta_x)\n",
    "    degree = abs(theta * (180 / m.pi)) \n",
    "    return degree\n",
    "\n",
    "def sendWarning():\n",
    "    \"\"\"Placeholder function for sending an alert.\"\"\"\n",
    "    print(\"Warning: Bad posture detected for too long!\")\n",
    "\n",
    "file_name = 'NeckPosture.avi'\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Couldn't open video file.\")\n",
    "    exit()\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "\n",
    "video_output = cv2.VideoWriter('output.avi', fourcc, fps, frame_size)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "green = (127, 255, 0)\n",
    "red = (50, 50, 255)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    "\n",
    "good_frames = 0\n",
    "bad_frames = 0\n",
    "\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "print(\"Processing...\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    keypoints = pose.process(image_rgb)\n",
    "\n",
    "    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Detect landmarks\n",
    "    if keypoints.pose_landmarks:\n",
    "        lm = keypoints.pose_landmarks.landmark\n",
    "        lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "        l_shldr_x, l_shldr_y = int(lm[lmPose.LEFT_SHOULDER].x * w), int(lm[lmPose.LEFT_SHOULDER].y * h)\n",
    "        r_shldr_x, r_shldr_y = int(lm[lmPose.RIGHT_SHOULDER].x * w), int(lm[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        l_ear_x, l_ear_y = int(lm[lmPose.LEFT_EAR].x * w), int(lm[lmPose.LEFT_EAR].y * h)\n",
    "        l_hip_x, l_hip_y = int(lm[lmPose.LEFT_HIP].x * w), int(lm[lmPose.LEFT_HIP].y * h)\n",
    "\n",
    "        # Calculate shoulder offset\n",
    "        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "        alignment_status = \"Aligned\" if offset < 100 else \"Not Aligned\"\n",
    "        #cv2.putText(image, f\"{int(offset)} {alignment_status}\", (w - 200, 30), font, 0.9, green if offset < 100 else red, 2)\n",
    "\n",
    "        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "\n",
    "        angle_text = f\"Neck: {int(neck_inclination)} degrees\"\n",
    "        if neck_inclination < 40 and torso_inclination < 10:\n",
    "            bad_frames = 0\n",
    "            good_frames += 1\n",
    "            color = green\n",
    "        else:\n",
    "            good_frames = 0\n",
    "            bad_frames += 1\n",
    "            color = red\n",
    "\n",
    "        cv2.putText(image, angle_text, (10, 30), font, 0.9, color, 2)\n",
    "        cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, color, 2)\n",
    "        cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, color, 2)\n",
    "\n",
    "        cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), color, 4)\n",
    "        cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), color, 4)\n",
    "\n",
    "        good_time = (1 / fps) * good_frames\n",
    "        bad_time = (1 / fps) * bad_frames\n",
    "\n",
    "        # Send warning if bad posture is held for too long\n",
    "        if bad_time > 180:\n",
    "            sendWarning()\n",
    "\n",
    "    video_output.write(image)\n",
    "\n",
    "print(\"Finished processing.\")\n",
    "cap.release()\n",
    "video_output.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bd6cd-a4af-4de6-bb9e-b143f328cf79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
